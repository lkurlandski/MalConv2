"""
Modify malware and record the classifier's response to the modified malware.
"""

from argparse import ArgumentParser
from configparser import ConfigParser
from datetime import datetime
from pathlib import Path
from pprint import pformat, pprint
import traceback
import typing as tp

import numpy as np
import matplotlib.pyplot as plt
import torch
from torch import Tensor
from tqdm import tqdm

from classifier import (
    CONFIDENCE_THRESHOLD,
    confidence_scores,
    get_model,
    MalConvLike,
    ModelName,
    NUM_EMBEDDINGS,
    PAD_VALUE,
    SOREL_TRAIN_PATH,
    WINDOWS_TRAIN_PATH,
    WINDOWS_TEST_PATH,
)
from config import device
from executable_helper import read_binary, text_section_bounds, text_section_data
from explain import BASELINE
from typing_ import ExeToolkit, Pathlike
from utils import ceil_divide, consume_until, error_line, get_outfile


MAX_INC_SUB_BYTES = 2**24  # 2 ^ 16 = 64 KB, 2 ^ 20 = 1 MB, 2 ^ 24 = 16 MB
BENIGN_FILES = [
    WINDOWS_TRAIN_PATH / f
    for f in [
        "701f928760a612a1e929551ca12363394922f30c7f8181f4df5b0ec0.exe",  # 9.903999e-06 malicious
        "f20a100e661a3179976ccf06ce4a773cbe8d19cd8f50f14e41c0a9e6.exe",  # 3.3748079e-06 malicious
        "09024e62ccab97df3b535e1d65025c54d2d8a684b9e6dcebba79786d.exe",  # 0.9886742 malicious
    ]
] + [
    WINDOWS_TEST_PATH / f
    for f in [
        "05efe7acbe79a7f925c5bc763d11f9d5a1daa2055d297436d0325a1b.exe",  # 1.6685235e-06 malicious
        "256838fe2f037b8865a49d0485c568923f561fea082aa5fa656d6b2d.exe",  # 0.043622814 malicious
        "efe6c4f2299bdc4b89ea935c05c8ebc740937cc7ee4a3948ba552a92.exe",  # 4.975618e-05 malicious
    ]
]
INC_MODES = [
    "inc_baseline",
    "inc_random",
    "inc_benign_corresponding",
    "inc_benign_least",
]
FULL_MODES = [
    "full_baseline",
    "full_random",
    "full_benign_corresponding",
    "full_benign_least",
]
MODES = INC_MODES + FULL_MODES


# TODO: untested
class GetLeastSuspiciousChunk:
    def __init__(
        self, X: Tensor, attributions: Tensor, chunk_size: int, suspicious_rank: int = 0
    ) -> None:
        self.X = X
        self.attributions = attributions
        self.chunk_size = chunk_size
        self.suspicious_rank = suspicious_rank
        self.sorted_start_of_chunks = get_sorted_starts_of_chunks(attributions, chunk_size)

    def __call__(self, suspicious_rank=None) -> Tensor:
        if suspicious_rank is None:
            suspicious_rank = self.suspicious_rank
            self.suspicious_rank += 1
        offset = self.sorted_start_of_chunks[suspicious_rank]
        return self.X[offset : offset + self.chunk_size]


# TODO: untested
def get_sorted_starts_of_chunks(chunked_tensor: Tensor, chunk_size: int) -> Tensor:
    offset = get_offset_chunk_tensor(chunked_tensor, chunk_size)
    start_of_chunks = torch.arange(offset, chunked_tensor.shape[0], chunk_size)
    start_of_chunks = torch.cat([Tensor([0]).to(torch.int64), start_of_chunks], axis=0)
    _, indices = torch.sort(chunked_tensor[start_of_chunks])
    return start_of_chunks[indices]


# TODO: untested
def get_offset_chunk_tensor(chunked_tensor: Tensor, chunk_size: int) -> int:
    first = chunked_tensor[0]
    for i in range(min(chunk_size, chunked_tensor.shape[0])):
        if chunked_tensor[i] != first:
            return i
    return 0


def swaps_count(
    attributions: Tensor,
    chunk_size: int,
    attribution_threshold: float = 0.0,
) -> int:
    n_over_thresh = torch.sum(attributions > attribution_threshold)
    return ceil_divide(n_over_thresh, chunk_size)


def get_output_path(
    params: ConfigParser,
    *,
    output_root: Pathlike = None,
    model_name: ModelName = None,
    max_len: int = None,
    chunk_size: int = None,
) -> Path:
    output_root = output_root if output_root is not None else params.get("output_root")
    model_name = model_name if model_name is not None else params.get("model_name")
    max_len = max_len if max_len is not None else params.get("max_len")
    chunk_size = chunk_size if chunk_size is not None else params.get("chunk_size")
    output_path = (
        Path(output_root)
        / model_name
        / str(max_len)
        / "KernelShap"
        / "False"
        / str(chunk_size)
        / "50"
        / "1"
    )
    return output_path


def get_least_suspicious_bounds(
    attributions: Tensor,
    block_size: int,
    suspicious_rank: int = 0,
) -> tp.Tuple[int, int]:
    """
    Get the upper and lower bounds of the least suspicious block of attributions.
    """
    if block_size > attributions.shape[0]:
        raise ValueError(
            f"The attribution vector is too short for the block size."
            f"Attribution vector length: {attributions.shape[0]}, block size: {block_size}"
        )
    # The sum of the attribution scores for a sliding window of size block_size
    block_scores = [
        torch.sum(attributions[i : i + block_size]).item()
        for i in range(0, attributions.shape[0] - block_size)
    ]
    _, indices_sorted_block_scores = torch.sort(Tensor(block_scores))
    l = indices_sorted_block_scores[suspicious_rank]
    return l, l + block_size


def slice_replacement_tensor(
    replacement: Tensor,
    size: int,
    mode: tp.Literal["exact", "truncate", "repeat", "pad"] = "repeat",
) -> Tensor:
    """
    Increase or decrease the size of the replacement tensor.
    """
    replacement = replacement.clone()
    if mode == "exact":
        replacement = replacement
    elif mode == "truncate":
        replacement = replacement[0:size]
    elif mode == "pad":
        padding = torch.full((size - replacement.shape[0],), PAD_VALUE)
        replacement = torch.cat((replacement, padding), 0)
    elif mode == "repeat":
        num_repeats = ceil_divide(size, replacement.shape[0])
        replacement = torch.cat([replacement for _ in range(num_repeats)], 0)[0:size]
    else:
        raise ValueError(f"Invalid mode: {mode}")
    return replacement


def incremental_substitute(
    run_flags: ConfigParser,
    model: MalConvLike,
    attributions: Tensor,
    X: Tensor,
    l: int,
    u: int,
    chunk_size: int,
    benign_replacement: tp.Optional[Tensor] = None,
    benign_attributions: tp.Optional[Tensor] = None,
    attribution_threshold: float = -float("inf"),
) -> tp.Tuple[tp.List[float]]:
    # Initial processes
    run_baseline, run_random, run_benign_corresponding, run_benign_least = [
        run_flags.getboolean("run_" + m) for m in INC_MODES
    ]
    if not any((run_baseline, run_random, run_benign_corresponding, run_benign_least)):
        return [], [], [], []
    attributions = attributions.clone()
    # Set up the return data structures of confidence scores
    baseline_confs = []
    random_confs = []
    benign_corresponding_confs = []
    benign_least_confs = []
    # Populate with the original confidence score
    c = confidence_scores(model, X).item()
    if run_baseline:
        baseline_confs = [c]
        baseline_X = X.clone()
    if run_random:
        random_confs = [c]
        random_X = X.clone()
    if run_benign_corresponding:
        benign_corresponding_confs = [c]
        benign_corresponding_X = X.clone()
    if run_benign_least:
        benign_least_confs = [c]
        benign_least_X = X.clone()
        get_least_suspicious_chunk = GetLeastSuspiciousChunk(X, attributions, chunk_size)
    # Upper limits on the number of swaps to perform in the loops
    max_swap_possible = ceil_divide(attributions.shape[0], chunk_size) + 1
    max_swap_limit = MAX_INC_SUB_BYTES // chunk_size
    for i in range(1, min(max_swap_possible, max_swap_limit)):
        try:
            # If the least suspicious chunk exceeds some threshold, stop
            if (max_attr := attributions.max()) <= attribution_threshold:
                break
            # Get the maximum attribution score and index it first occurs (torch version stable)
            max_attr_lower = (max_attr == attributions).nonzero()[0].item()
            attributions[max_attr_lower : max_attr_lower + chunk_size] = -float("inf")
            # Get the lower and upper bounds and replacement value for the full input tensor
            l_replace = min(u, l + max_attr_lower)
            u_replace = min(u, l + max_attr_lower + chunk_size)
            size = u_replace - l_replace
            # Compute the replacement tensors and new confidence scores
            if run_baseline:
                r = torch.full((size,), BASELINE)
                baseline_X[l_replace:u_replace] = r
                baseline_confs.append(confidence_scores(model, baseline_X).item())
            if run_random:
                r = torch.randint(low=0, high=NUM_EMBEDDINGS, size=(size,))
                random_X[l_replace:u_replace] = r
                random_confs.append(confidence_scores(model, random_X).item())
            if run_benign_corresponding:
                r = slice_replacement_tensor(benign_replacement, max_attr_lower + size)[
                    max_attr_lower : max_attr_lower + size
                ]
                benign_corresponding_X[l_replace:u_replace] = r
                benign_corresponding_confs.append(
                    confidence_scores(model, benign_corresponding_X).item()
                )
            # TODO: untested
            if run_benign_least:
                r = get_least_suspicious_chunk()
                benign_least_X[l_replace:u_replace] = r[0:size]
                benign_least_confs.append(confidence_scores(model, benign_least_X).item())
        except Exception as e:
            raise type(e)(e.message + f"\nlocals:\n{pformat(locals())}")

    return baseline_confs, random_confs, benign_corresponding_confs, benign_least_confs


def full_substitute(
    run_flags: ConfigParser,
    model: MalConvLike,
    X: Tensor,
    l: int,
    u: int,
    benign_replacement: tp.Optional[Tensor] = None,
    benign_attributions: tp.Optional[Tensor] = None,
    mode: tp.Literal["exact", "truncate", "repeat", "pad"] = "repeat",
) -> tp.Tuple[tp.List[float]]:
    # Initial processes
    run_baseline, run_random, run_benign_corresponding, run_benign_least = [
        run_flags.getboolean("run_" + m) for m in FULL_MODES
    ]
    if not any((run_baseline, run_random, run_benign_corresponding, run_benign_least)):
        return [], [], [], []
    # Set up the return data structures of confidence scores
    baseline_confs = []
    random_confs = []
    benign_corresponding_confs = []
    benign_least_confs = []
    # Size of the input's .text section and original confidence score
    size = u - l
    c = confidence_scores(model, X).item()
    # Populate with the original confidence score
    if run_baseline:
        X_ = X.clone()
        X_[l:u] = torch.full((size,), BASELINE)
        baseline_confs = [c, confidence_scores(model, X_).item()]
    if run_random:
        X_ = X.clone()
        X_[l:u] = torch.randint(low=0, high=NUM_EMBEDDINGS, size=(size,))
        random_confs = [c, confidence_scores(model, X_).item()]
    if run_benign_corresponding:
        X_ = X.clone()
        X_[l:u] = slice_replacement_tensor(benign_replacement, size, mode)
        benign_corresponding_confs = [c, confidence_scores(model, X_).item()]
    # TODO: untested
    if run_benign_least:
        X_ = X.clone()
        l_, u_ = get_least_suspicious_bounds(benign_attributions, size)
        X_[l:u] = benign_replacement[l_:u_]
        benign_least_confs = [c, confidence_scores(model, X_).item()]

    return baseline_confs, random_confs, benign_corresponding_confs, benign_least_confs


def run_per_sample(
    run_flags,
    chunk_size: int,
    model: MalConvLike,
    attributions_path: Path,
    confidences_path: Path,
    f: Path,
    l: int,
    u: int,
    benign_replacement: tp.Optional[Tensor] = None,
    benign_attributions: tp.Optional[Tensor] = None,
) -> None:
    try:

        attributions_file = attributions_path / f"{f.name}.pt"
        attributions = torch.load(attributions_file, map_location=device)[l:u]
        if get_offset_chunk_tensor(attributions, chunk_size) != 0:
            o = get_offset_chunk_tensor(attributions, chunk_size)
            raise ValueError(f"attributions have nonzero chunk offset {o=}")
        X = Tensor(read_binary(f))

        inc_values = incremental_substitute(
            run_flags,
            model,
            attributions,
            X,
            l,
            u,
            chunk_size,
            benign_replacement=benign_replacement,
            benign_attributions=benign_attributions,
        )

        full_values = full_substitute(
            run_flags,
            model,
            X,
            l,
            u,
            benign_replacement=benign_replacement,
            benign_attributions=benign_attributions,
        )

        for m, conf in zip(MODES, inc_values + full_values):
            if conf:
                p = confidences_path / m / f"{f.name}.txt"
                p.parent.mkdir(exist_ok=True, parents=True)
                np.savetxt(p, conf, delimiter="\n")

    except Exception as e:
        s = "\n".join(
            [
                error_line(),
                f"f={f.as_posix()}",
                str(e),
                traceback.format_exc(),
                f"\nlocals:\n{pformat(locals())}",
                error_line(),
            ]
        )
        print(s)


def run(run_flags: ConfigParser, params: ConfigParser, control: ConfigParser) -> None:

    print(f"run START @{datetime.now()}")

    output_path = get_output_path(params)
    model_name = params.get("model_name")
    chunk_size = params.getint("chunk_size")
    toolkit = params.get("toolkit")
    min_size = int(params.get("min_size")) if params.get("min_size") is not None else None
    max_size = int(params.get("max_size")) if params.get("max_size") is not None else None
    n_workers = control.getint("n_workers")
    skip_idx = int(control.get("skip_idx")) if control.get("skip_idx") is not None else None
    skip_val = control.get("skip_val")

    model = get_model(model_name)
    # TODO: use multiple benign files
    _, _, _, benign_replacement = next(text_section_data(BENIGN_FILES[5], toolkit, "torch"))
    # TODO: get benign_attributions
    benign_attributions = None

    attributions_path = output_path / "attributions"
    confidences_path = output_path / "confidences" / toolkit
    confidences_path.mkdir(parents=True, exist_ok=True)

    files_and_bounds = text_section_bounds(
        SOREL_TRAIN_PATH.iterdir(),
        toolkit,
        min_size=min_size,
        max_size=max_size,
        errors="ignore",
    )
    per_sample_arguments = (
        (
            run_flags,
            chunk_size,
            model,
            attributions_path,
            confidences_path,
            f,
            l,
            u,
            benign_replacement,
            benign_attributions,
        )
        for f, l, u in files_and_bounds
    )

    if skip_idx or skip_val:
        consume_until(per_sample_arguments, skip_idx, skip_val, lambda x: x[5].as_posix())

    if n_workers > 1:
        from utils import istarmap
        import multiprocessing.pool as mpp

        mpp.Pool.istarmap = istarmap
        from multiprocessing import Pool

        with Pool(processes=n_workers) as pool:
            for _ in tqdm(pool.istarmap(run_per_sample, per_sample_arguments), total=1500):
                pass
    else:
        for r_f, c_s, m, a_p, c_p, f, l, u, b_r, b_a in tqdm(per_sample_arguments, total=1500):
            run_per_sample(r_f, c_s, m, a_p, c_p, f, l, u, b_r, b_a)
            # if run_flags.getboolean("run_swaps_count"):
            #     attributions_file = attributions_path / f"{f.name}.pt"
            #     attributions = torch.load(attributions_file, map_location=device)[l:u]
            #     threshold = 0.0
            #     n_swaps = swaps_count(attributions, chunk_size, threshold)
            #     swaps_count_log = output_path / f"swaps_count_{threshold}.txt"
            #     with open(swaps_count_log, "a") as handle:
            #         handle.write(f"{f.as_posix()}, {n_swaps}\n")

    print(f"run DONE @{datetime.now()}")


def plot_proportion_negative_vs_swap_absolute(
    data: tp.Dict[str, np.ndarray],
    chunk_size: int,
    mode: tp.Literal["last", "any"],
    **outfile_kwargs,
) -> None:
    lengths = {k: len(confs) for k, confs in data.items()}
    max_iterations = max(lengths.values())
    n_neg_clfs = np.zeros(max_iterations)
    for itr in range(max_iterations):
        for k, confs in sorted(data.items(), key=lambda x: x[0]):
            if mode == "any":
                if any(c < CONFIDENCE_THRESHOLD for c in confs[:itr]):
                    n_neg_clfs[itr] += 1
            elif mode == "last":
                c = confs[itr] if itr < lengths[k] else confs[-1]
                if c < CONFIDENCE_THRESHOLD:
                    n_neg_clfs[itr] += 1
            else:
                raise ValueError(f"Invalid mode: {mode}")

    p_neg_clfs = n_neg_clfs / len(data)

    # Plot one
    fig, ax = plt.subplots()
    ax.plot(chunk_size * np.arange(max_iterations), 100 * p_neg_clfs)
    ax.set_title("False Negative Classification vs Bytes Swapped")
    ax.set_xlabel("Bytes Swapped in .text Section")
    ax.set_ylabel("Percent Classified as Benign")

    if "outfile_stem" not in outfile_kwargs:
        outfile_kwargs["outfile_stem"] = f"proportion_negative_vs_swap_absolute_{mode}"
    if "outfile_suffix" not in outfile_kwargs:
        outfile_kwargs["outfile_suffix"] = ".png"
    fig.savefig(get_outfile(**outfile_kwargs), dpi=400)


def plot_proportion_negative_vs_swap_proportion(
    data: tp.Dict[str, np.ndarray],
    mode: tp.Literal["last", "any"],
    granularity: int = 100,
    **outfile_kwargs,
) -> None:
    n_neg_clfs = np.zeros(granularity)

    for p in range(granularity):
        for k, confs in sorted(data.items(), key=lambda x: x[0]):
            itr = p * len(confs) // granularity
            if mode == "any":
                if any(c < CONFIDENCE_THRESHOLD for c in confs[:itr]):
                    n_neg_clfs[p] += 1
            elif mode == "last":
                c = confs[itr]
                if c < CONFIDENCE_THRESHOLD:
                    n_neg_clfs[p] += 1
            else:
                raise ValueError(f"Invalid mode: {mode}")

    p_neg_clfs = n_neg_clfs / len(data)

    # Plot one
    fig, ax = plt.subplots()
    ax.plot(np.arange(granularity), 100 * p_neg_clfs)
    ax.set_title("False Negative Classification vs Bytes Swapped")
    ax.set_xlabel("Percent Bytes Swapped in .text Section")
    ax.set_ylabel("Percent Classified as Benign")

    if "outfile_stem" not in outfile_kwargs:
        outfile_kwargs["outfile_stem"] = f"proportion_negative_vs_swap_proportion_{mode}"
    if "outfile_suffix" not in outfile_kwargs:
        outfile_kwargs["outfile_suffix"] = ".png"
    fig.savefig(get_outfile(**outfile_kwargs), dpi=400)


def analyze(run_flags: ConfigParser, params: ConfigParser) -> None:
    output_path = get_output_path(params)
    toolkit = params.get("toolkit")
    chunk_size = params.get("chunk_size")

    confidences_path = output_path / "confidences" / toolkit
    analysis_path = confidences_path / "analysis"
    modes_paths = {confidences_path / m for m in MODES if run_flags.getboolean("run_" + m, False)}

    avg_conf_diff, prop_cls_flipped = {}, {}
    for m in tqdm(modes_paths):
        files = list(modes_paths[m].iterdir())
        init_tp, init_fp, conf_diff, num_flipped = 0, 0, 0, 0
        confs_data = {}
        for f in tqdm(files, leave=False):
            confs = np.loadtxt(f, delimiter="\n")
            confs = np.expand_dims(confs, axis=0) if not confs.shape else confs
            confs_data[f.stem] = confs
            if len(confs) > 1 and confs[0] > CONFIDENCE_THRESHOLD:
                conf_diff += confs[-1] - confs[0]
                init_tp += 1
                if confs[-1] < CONFIDENCE_THRESHOLD:
                    num_flipped += 1
            else:
                init_fp += 1
        plot_proportion_negative_vs_swap_absolute(
            confs_data,
            chunk_size,
            "any",
            outfile_parent=analysis_path / m,
        )
        plot_proportion_negative_vs_swap_absolute(
            confs_data,
            chunk_size,
            "last",
            outfile_parent=analysis_path / m,
        )
        plot_proportion_negative_vs_swap_proportion(
            confs_data,
            "any",
            outfile_parent=analysis_path / m,
        )
        plot_proportion_negative_vs_swap_proportion(
            confs_data,
            "last",
            outfile_parent=analysis_path / m,
        )
        avg_conf_diff[m] = conf_diff / init_tp
        prop_cls_flipped[m] = num_flipped / init_tp

    return {
        "avg_conf_diff": avg_conf_diff,
        "prop_cls_flipped": prop_cls_flipped,
        "init_tp": init_tp,
        "init_fp": init_fp,
    }


def _verify_inc_and_full_same():
    # Only differences should be in the random method
    root = Path("outputs/7/KernelShap/False/256/50/1/confidences/pefile")
    paths = {
        "baseline": (root / "inc_baseline", root / "full_baseline"),
        "random": (root / "inc_random", root / "full_random"),
        "benign": (
            root / "inc_benign_corresponding",
            root / "full_benign_corresponding",
        ),
    }
    data = {k: [] for k in paths}
    for k, (inc_path, full_path) in paths.items():
        for f_inc in inc_path.iterdir():
            f_full = full_path / f_inc.name
            inc = np.loadtxt(f_inc, delimiter="\n")
            full = np.loadtxt(f_full, delimiter="\n")
            if not inc.shape:
                print(f_inc)
            if not full.shape:
                print(f_full)
            inc = np.expand_dims(inc, 0) if not inc.shape else inc
            full = np.expand_dims(full, 0) if not inc.shape else inc
            if inc[-1] != full[-1]:
                data[k].append((f_inc.name, inc, full))
    return data


if __name__ == "__main__":
    parser = ArgumentParser()
    parser.add_argument("--config_file", type=str, default="config_files/modify_malware/basic.ini")
    args = parser.parse_args()

    config = ConfigParser(allow_no_value=True)
    config.read(args.config_file)

    run_flags = config["RUN_FLAGS"]
    control = config["CONTROL"]
    params = config["PARAMS"]

    if run_flags.getboolean("run_inc_benign_least") or run_flags.getboolean(
        "run_full_benign_least"
    ):
        raise NotImplementedError()

    if run_flags.getboolean("run"):
        run(run_flags, params, control)
    if run_flags.getboolean("analyze"):
        results = analyze(run_flags, params)
        pprint(results)
