"""
Modify malware and record the classifier's response to the modified malware.
"""

from argparse import ArgumentParser
from configparser import ConfigParser, SectionProxy
from datetime import datetime
from itertools import chain
import multiprocessing
import os
from pathlib import Path
from pprint import pformat, pprint
from random import shuffle
import time
import typing as tp

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import torch
from torch import Tensor
from tqdm import tqdm

from classifier import (
    CONFIDENCE_THRESHOLD,
    confidence_scores,
    get_model,
    MalConvLike,
    ModelName,
    NUM_EMBEDDINGS,
    PAD_VALUE,
    SOREL_TEST_PATH,
    SOREL_TRAIN_PATH,
    WINDOWS_TEST_PATH,
    WINDOWS_TRAIN_PATH,
)
from config import device
from executable_helper import (
    read_binary,
    stream_text_section_data,
    generate_text_section_bounds_file,
)
from explain import BASELINE
from typing_ import ErrorMode, ExeToolkit, Pathlike
from utils import batch, ceil_divide, exception_info, get_outfile, raise_error


MAX_INC_SUB_BYTES = 2**24  # 2 ^ 16 = 64 KB, 2 ^ 20 = 1 MB, 2 ^ 24 = 16 MB
BENIGN_FILES = [
    WINDOWS_TRAIN_PATH / f
    for f in [
        "f20a100e661a3179976ccf06ce4a773cbe8d19cd8f50f14e41c0a9e6.exe",  # 3.3748079e-06 malicious
        "09024e62ccab97df3b535e1d65025c54d2d8a684b9e6dcebba79786d.exe",  # 0.9886742 malicious
    ]
] + [
    WINDOWS_TEST_PATH / f
    for f in [
        "05efe7acbe79a7f925c5bc763d11f9d5a1daa2055d297436d0325a1b.exe",  # 1.6685235e-06 malicious
        "256838fe2f037b8865a49d0485c568923f561fea082aa5fa656d6b2d.exe",  # 0.043622814 malicious
        "efe6c4f2299bdc4b89ea935c05c8ebc740937cc7ee4a3948ba552a92.exe",  # 4.975618e-05 malicious
        "701f928760a612a1e929551ca12363394922f30c7f8181f4df5b0ec0.exe",  # 9.903999e-06 malicious
    ]
]
GOOD_BENIGN_FILES = [
    # avg full_benign_corresponding .51 & avg_flipped_corresponding .45%
    WINDOWS_TEST_PATH / "53e17b21d2ff8fa5732211eed9f74f591b9bff985e79f6ad6b85bb72.exe",
    # avg full_benign_corresponding .61 & avg_flipped_corresponding .35%
    WINDOWS_TRAIN_PATH / "fedccb36656858a3aded2b756c7f8d2afa94236140f9defa1d51d1d7.exe",
]
INC_MODES = [
    "inc_baseline",
    "inc_random",
    "inc_benign_corresponding",
    "inc_benign_least",
]
FULL_MODES = [
    "full_baseline",
    "full_random",
    "full_benign_corresponding",
    "full_benign_least",
]
MULTI_FULL_MODES = ["multi_full_benign_corresponding", "multi_full_benign_least"]


class TextSectionAttributionsIterable:
    def __init__(
        self,
        files: tp.Iterable[Path],
        toolkit: ExeToolkit,
        attributions_path: tp.Optional[Path],
        n: int = None,
        shuffle_: bool = True,
    ) -> None:
        self.toolkit = toolkit
        self.attributions_path = attributions_path
        self.n = n
        self.files = list(files)
        if shuffle_:
            shuffle(self.files)

    def __call__(self) -> tp.Generator[tp.Tuple[Path, int, int, Tensor, Tensor], None, None]:
        attributions = None
        gen = stream_text_section_data(self.files, self.toolkit, "torch", max_size=1000000)
        for i, (f, l, u, x) in enumerate(gen, 1):
            if self.n is not None and i > self.n:
                return
            if self.attributions_path is not None:
                attributions = get_text_section_attributions(self.attributions_path, f.name, l, u)
            yield f, l, u, x, attributions


class GetLeastSuspiciousChunk:
    def __init__(
        self, X: Tensor, attributions: Tensor, chunk_size: int, suspicious_rank: int = 0
    ) -> None:
        """
        Acquire the least suspicious chunk from X using the corresponding attributions.
        """
        if X.shape != attributions.shape:
            raise ValueError(f"X.shape != attributions.shape: {X.shape} != {attributions.shape}")
        self.X = X
        self.attributions = attributions
        self.chunk_size = chunk_size
        self.suspicious_rank = suspicious_rank
        self.sorted_start_of_chunks = get_sorted_starts_of_chunks(attributions, chunk_size)

    def __call__(self, suspicious_rank=None) -> Tensor:
        if suspicious_rank is None:
            suspicious_rank = self.suspicious_rank
            self.suspicious_rank += 1
        offset = self.sorted_start_of_chunks[suspicious_rank]
        return self.X[offset : offset + self.chunk_size]


def get_sorted_starts_of_chunks(chunked_tensor: Tensor, chunk_size: int) -> Tensor:
    """Get the indices within a chunked tensor that correspond to the sorted chunk values."""
    offset = get_offset_chunk_tensor(chunked_tensor, chunk_size)
    start_of_chunks = torch.arange(offset, chunked_tensor.shape[0], chunk_size)
    if offset != 0:
        start_of_chunks = torch.cat([Tensor([0]).to(torch.int64), start_of_chunks], axis=0)
    _, indices = torch.sort(chunked_tensor[start_of_chunks])
    return start_of_chunks[indices]


def get_offset_chunk_tensor(chunked_tensor: Tensor, chunk_size: int) -> int:
    first = chunked_tensor[0]
    for i in range(min(chunk_size, chunked_tensor.shape[0])):
        if chunked_tensor[i] != first:
            return i
    return 0


def swaps_count(
    attributions: Tensor,
    chunk_size: int,
    attribution_threshold: float = 0.0,
) -> int:
    n_over_thresh = torch.sum(attributions > attribution_threshold)
    return ceil_divide(n_over_thresh, chunk_size)


def get_output_path(
    params: SectionProxy,
    *,
    output_root: Pathlike = None,
    model_name: ModelName = None,
    max_len: int = None,
    softmax: bool = None,
    chunk_size: int = None,
) -> Path:
    output_root = output_root if output_root is not None else params.get("output_root")
    model_name = model_name if model_name is not None else params.get("model_name")
    max_len = max_len if max_len is not None else params.get("max_len")
    softmax = softmax if softmax is not None else params.getboolean("softmax")
    chunk_size = chunk_size if chunk_size is not None else params.get("chunk_size")
    output_path = (
        Path(output_root)
        / model_name
        / str(max_len)
        / "KernelShap"
        / str(softmax)
        / str(chunk_size)
        / "50"
        / "1"
    )
    return output_path


def get_least_suspicious_bounds(
    attributions: Tensor,
    block_size: int,
    suspicious_rank: int = 0,
) -> tp.Tuple[int, int]:
    """
    Get the upper and lower bounds of the least suspicious block of attributions.
    """
    if block_size > attributions.shape[0]:
        raise ValueError(
            f"The attribution vector is too short for the block size."
            f"Attribution vector length: {attributions.shape[0]}, block size: {block_size}"
        )
    # The sum of the attribution scores for a sliding window of size block_size
    block_scores = [
        torch.sum(attributions[i : i + block_size]).item()
        for i in range(attributions.shape[0] - block_size + 1)
    ]
    _, indices_sorted_block_scores = torch.sort(Tensor(block_scores))
    l = indices_sorted_block_scores[suspicious_rank]
    return l, l + block_size


# TODO: rename and simplify the responsibilities of this function
def slice_replacement_tensor(
    replacement: Tensor,
    size: int,
    mode: tp.Literal["exact", "truncate", "repeat", "pad"] = "repeat",
) -> Tensor:
    """
    Increase or decrease the size of the replacement tensor.
    """
    replacement = replacement.clone()
    if mode == "exact":
        replacement = replacement
    elif mode == "truncate":
        replacement = replacement[0:size]
    elif mode == "pad":
        padding = torch.full((size - replacement.shape[0],), PAD_VALUE)
        replacement = torch.cat((replacement, padding), 0)
    elif mode == "repeat":
        num_repeats = ceil_divide(size, replacement.shape[0])
        replacement = torch.cat([replacement for _ in range(num_repeats)], 0)[0:size]
    else:
        raise ValueError(f"Invalid mode: {mode}")
    return replacement


# TODO: implement batched evaluation
def incremental_substitute(
    run_flags: SectionProxy,
    model: MalConvLike,
    attributions: Tensor,
    X: Tensor,
    l: int,
    u: int,
    chunk_size: int,
    benign_replacement: tp.Optional[Tensor] = None,
    benign_attributions: tp.Optional[Tensor] = None,
    attribution_threshold: float = -float("inf"),
) -> tp.Tuple[tp.List[float]]:
    # Initial processes
    run_baseline, run_random, run_benign_corresponding, run_benign_least = [
        run_flags.getboolean("run_" + m) for m in INC_MODES
    ]
    if not any((run_baseline, run_random, run_benign_corresponding, run_benign_least)):
        return [], [], [], []
    attributions = attributions.clone()
    # ensure the size of the benign replacement is the same as the input's .text section
    if benign_replacement is not None or benign_attributions is not None:
        size = ceil_divide(u - l, chunk_size) * chunk_size
        if benign_replacement is not None:
            benign_replacement = slice_replacement_tensor(benign_replacement, size)
        if benign_attributions is not None:
            benign_attributions = slice_replacement_tensor(benign_attributions, size)
    # Set up the return data structures of confidence scores
    baseline_confs = []
    random_confs = []
    benign_corresponding_confs = []
    benign_least_confs = []
    # Populate with the original confidence score
    c = confidence_scores(model, X).item()
    if run_baseline:
        baseline_confs = [c]
        baseline_X = X.clone()
    if run_random:
        random_confs = [c]
        random_X = X.clone()
    if run_benign_corresponding:
        benign_corresponding_confs = [c]
        benign_corresponding_X = X.clone()
    if run_benign_least:
        benign_least_confs = [c]
        benign_least_X = X.clone()
        get_least_suspicious_chunk = GetLeastSuspiciousChunk(
            benign_replacement, benign_attributions, chunk_size
        )
    # Upper limits on the number of swaps to perform in the loops
    max_swap_possible = ceil_divide(attributions.shape[0], chunk_size) + 1
    max_swap_limit = MAX_INC_SUB_BYTES // chunk_size
    for i in range(1, min(max_swap_possible, max_swap_limit)):
        try:
            # If the least suspicious chunk exceeds some threshold, stop
            if (max_attr := attributions.max()) <= attribution_threshold:
                break
            # Get the maximum attribution score and index it first occurs (torch version stable)
            max_attr_lower = (max_attr == attributions).nonzero()[0].item()
            attributions[max_attr_lower : max_attr_lower + chunk_size] = -float("inf")
            # Get the lower and upper bounds and replacement value for the full input tensor
            l_replace = min(u, l + max_attr_lower)
            u_replace = min(u, l + max_attr_lower + chunk_size)
            size = u_replace - l_replace
            # Compute the replacement tensors and new confidence scores
            if run_baseline:
                r = torch.full((size,), BASELINE)
                baseline_X[l_replace:u_replace] = r
                c = confidence_scores(model, baseline_X).item()
                baseline_confs.append(c)
            if run_random:
                r = torch.randint(low=0, high=NUM_EMBEDDINGS, size=(size,))
                random_X[l_replace:u_replace] = r
                c = confidence_scores(model, random_X).item()
                random_confs.append(c)
            if run_benign_corresponding:
                # r = slice_replacement_tensor(benign_replacement, max_attr_lower + size)
                r = benign_replacement[max_attr_lower : max_attr_lower + size]
                benign_corresponding_X[l_replace:u_replace] = r
                c = confidence_scores(model, benign_corresponding_X).item()
                benign_corresponding_confs.append(c)
            if run_benign_least:
                r = get_least_suspicious_chunk()
                r = r[0:size]
                benign_least_X[l_replace:u_replace] = r
                c = confidence_scores(model, benign_least_X).item()
                benign_least_confs.append(c)
        except Exception as e:
            print(exception_info(e, locals()))
            raise_error(e, pre="incremental_substitute")

    return baseline_confs, random_confs, benign_corresponding_confs, benign_least_confs


def full_benign_least_replacement(
    benign_replacement: Tensor,
    benign_attributions: Tensor,
    size: int,
    mode: tp.Literal["exact", "truncate", "repeat", "pad"],
) -> Tensor:
    benign_attributions = slice_replacement_tensor(
        benign_attributions, max(size, benign_attributions.shape[0]), mode
    )
    benign_replacement = slice_replacement_tensor(
        benign_replacement, max(size, benign_replacement.shape[0]), mode
    )
    l, u = get_least_suspicious_bounds(benign_attributions, size)
    return benign_replacement[l:u]


def full_substitute(
    run_flags: SectionProxy,
    model: MalConvLike,
    X: Tensor,
    l: int,
    u: int,
    benign_replacement: tp.Optional[Tensor] = None,
    benign_attributions: tp.Optional[Tensor] = None,
    mode: tp.Literal["exact", "truncate", "repeat", "pad"] = "repeat",
) -> tp.Tuple[tp.List[float]]:
    # Initial processes
    run_baseline, run_random, run_benign_corresponding, run_benign_least = [
        run_flags.getboolean("run_" + m) for m in FULL_MODES
    ]
    if not any((run_baseline, run_random, run_benign_corresponding, run_benign_least)):
        return [], [], [], []
    # Set up the return data structures of confidence scores
    baseline_confs = []
    random_confs = []
    benign_corresponding_confs = []
    benign_least_confs = []
    # Size of the input's .text section and original confidence score
    size = u - l
    c = confidence_scores(model, X).item()
    # Populate with the original confidence score
    if run_baseline:
        X_ = X.clone()
        X_[l:u] = torch.full((size,), BASELINE)
        baseline_confs = [c, confidence_scores(model, X_).item()]
    if run_random:
        X_ = X.clone()
        X_[l:u] = torch.randint(low=0, high=NUM_EMBEDDINGS, size=(size,))
        random_confs = [c, confidence_scores(model, X_).item()]
    if run_benign_corresponding:  # TODO: duplicated code
        X_ = X.clone()
        X_[l:u] = slice_replacement_tensor(benign_replacement, size, mode)
        benign_corresponding_confs = [c, confidence_scores(model, X_).item()]
    if run_benign_least:
        X_ = X.clone()
        X_[l:u] = full_benign_least_replacement(benign_replacement, benign_attributions, size, mode)
        benign_least_confs = [c, confidence_scores(model, X_).item()]

    return baseline_confs, random_confs, benign_corresponding_confs, benign_least_confs


# TODO: implement batched evaluation
# TODO: do not include the model's original confidence score?
def multi_full_substitute(
    run_flags: SectionProxy,
    model: MalConvLike,
    X: Tensor,
    l: int,
    u: int,
    text_section_bounds: tp.Dict[str, tp.Tuple[int, int]],
    benign_files: tp.Iterable[Path],
    attributions_path: Path,
    mode: tp.Literal["exact", "truncate", "repeat", "pad"] = "repeat",
) -> tp.Tuple[tp.List[Path], tp.List[float], tp.List[float]]:
    # Initial processes
    run_benign_corresponding = run_flags.getboolean("run_multi_full_benign_corresponding")
    run_benign_least = run_flags.getboolean("run_multi_full_benign_least")
    if not any((run_benign_corresponding, run_benign_least)):
        return [], [], []
    # Size of the input's .text section and original confidence score
    size = u - l
    c = confidence_scores(model, X).item()
    used_files = [None]
    benign_corresponding_confs = [c] if run_benign_corresponding else []
    benign_least_confs = [c] if run_benign_least else []

    for br_f in benign_files:
        br_l, br_u = text_section_bounds[br_f.as_posix()]
        used_files.append(br_f)
        br_X = Tensor(read_binary(br_f, l=br_l, u=br_u))
        br_A = get_text_section_attributions(attributions_path, br_f.name, br_l, br_u)
        if run_benign_corresponding:
            X_ = X.clone()
            X_[l:u] = slice_replacement_tensor(br_X, size, mode)
            benign_corresponding_confs.append(confidence_scores(model, X_).item())
        if run_benign_least:
            X_ = X.clone()
            X_[l:u] = full_benign_least_replacement(br_X, br_A, size, mode)
            benign_least_confs.append(confidence_scores(model, X_).item())

    return used_files, benign_corresponding_confs, benign_least_confs


def get_text_section_attributions(
    attributions_path: Path,
    exe_name: str,
    l: int,
    u: int,
) -> Tensor:
    f_1 = attributions_path / "benign" / f"{exe_name}.pt"
    f_2 = attributions_path / "malicious" / f"{exe_name}.pt"
    if f_1.exists() and f_2.exists():
        raise ValueError(f"Attributions file in both benign/malicious directories: {exe_name=}")
    elif f_1.exists():
        f = f_1
    elif f_2.exists():
        f = f_2
    else:
        raise FileNotFoundError(
            f"Attributions file not in either benign/malicious directories: {exe_name=}"
        )

    return torch.load(f, map_location=device)[l:u]


def run_sample(
    run_flags: SectionProxy,
    chunk_size: int,
    model: MalConvLike,
    attributions_path: Path,
    confidences_path: Path,
    text_section_bounds: tp.Dict[str, tp.Tuple[int, int]],
    f: Path,
    benign_replacement: tp.Optional[Tensor] = None,
    benign_attributions: tp.Optional[Tensor] = None,
    benign_files: tp.Iterable[Path] = None,
    errors: ErrorMode = "warn",
) -> None:
    try:
        l, u = text_section_bounds[f.as_posix()]
        attributions = get_text_section_attributions(attributions_path, f.name, l, u)
        if get_offset_chunk_tensor(attributions, chunk_size) != 0:
            o = get_offset_chunk_tensor(attributions, chunk_size)
            raise ValueError(f"attributions have nonzero chunk offset {o=}")
        X = Tensor(read_binary(f))

        inc_values = incremental_substitute(
            run_flags,
            model,
            attributions,
            X,
            l,
            u,
            chunk_size,
            benign_replacement=benign_replacement,
            benign_attributions=benign_attributions,
        )

        full_values = full_substitute(
            run_flags,
            model,
            X,
            l,
            u,
            benign_replacement=benign_replacement,
            benign_attributions=benign_attributions,
        )

        multi_full_values = multi_full_substitute(
            run_flags,
            model,
            X,
            l,
            u,
            text_section_bounds,
            benign_files,
            attributions_path,
        )

        for m, conf in zip(INC_MODES + FULL_MODES, inc_values + full_values):
            if conf:
                p = confidences_path / m / f"{f.name}.txt"
                p.parent.mkdir(exist_ok=True, parents=True)
                np.savetxt(p, conf, delimiter="\n")

        if multi_full_values[1]:
            p = confidences_path / "multi_full_benign_corresponding" / f"{f.name}.csv"
            p.parent.mkdir(exist_ok=True, parents=True)
            pd.DataFrame(
                {"substitute": multi_full_values[0], "confidences": multi_full_values[1]}
            ).to_csv(p, index=False)
        if multi_full_values[2]:
            p = confidences_path / "multi_full_benign_least" / f"{f.name}.csv"
            p.parent.mkdir(exist_ok=True, parents=True)
            pd.DataFrame(
                {"substitute": multi_full_values[0], "confidences": multi_full_values[2]}
            ).to_csv(p, index=False)

    except Exception as e:
        if errors == "warn":
            locals_ = locals()
            locals_.pop("text_section_bounds")
            print(exception_info(e, locals_))
        elif errors == "ignore":
            pass
        else:
            raise e


def run_samples(
    mal_files: tp.Iterable[Path],
    run_flags: SectionProxy,
    chunk_size: int,
    model: MalConvLike,
    attributions_path: Path,
    confidences_path: Path,
    text_section_bounds: tp.Dict[str, tp.Tuple[int, int]],
    benign_replacement: tp.Optional[Tensor] = None,
    benign_attributions: tp.Optional[Tensor] = None,
    benign_files: tp.Iterable[Path] = None,
    errors: ErrorMode = "warn",
    verbose: bool = False,
):
    args = (
        (
            run_flags,
            chunk_size,
            model,
            attributions_path,
            confidences_path,
            text_section_bounds,
            f,
            benign_replacement,
            benign_attributions,
            benign_files,
            errors,
        )
        for f in mal_files
    )
    for arg in tqdm(args, total=len(mal_files)):
        start = time.time()
        run_sample(*arg)
        if verbose:
            print(
                f"PID={os.getpid()} "
                f"DONE={arg[7].name} "
                f"@{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} "
                f"in {time.time() - start:.2f}s "
            )


def run(run_flags: SectionProxy, params: SectionProxy, control: SectionProxy) -> None:

    output_path = get_output_path(params)
    model_name = params.get("model_name")
    chunk_size = params.getint("chunk_size")
    toolkit = params.get("toolkit")
    min_size = int(params.get("min_size")) if params.get("min_size") is not None else None
    max_size = int(params.get("max_size")) if params.get("max_size") is not None else None
    n_benign = int(params.getint("n_benign")) if params.get("n_benign") is not None else None
    n_workers = control.getint("n_workers")
    skip_idx = int(control.get("skip_idx")) if control.get("skip_idx") is not None else 0
    skip_val = control.get("skip_val")
    text_section_bounds_file = control.get("text_section_bounds_file")

    attributions_path = output_path / "attributions"
    confidences_path = output_path / "confidences" / toolkit
    confidences_path.mkdir(parents=True, exist_ok=True)

    model = get_model(model_name)
    # Single benign replacement file for use with the incremental substitution methods
    br_f, br_l, br_u, br_d = next(stream_text_section_data(GOOD_BENIGN_FILES[0], toolkit, "torch"))
    br_a = get_text_section_attributions(attributions_path, br_f.name, br_l, br_u)

    # Full list of files to be used, which will be truncated shortly
    mal_files = list(chain(SOREL_TRAIN_PATH.iterdir(), SOREL_TEST_PATH.iterdir()))
    ben_files = list(chain(WINDOWS_TRAIN_PATH.iterdir(), WINDOWS_TEST_PATH.iterdir()))

    if text_section_bounds_file is None:
        text_section_bounds_file = (
            Path(params.get("output_root")) / f"text_section_bounds_{toolkit}.csv"
        )
        if not text_section_bounds_file.exists():
            generate_text_section_bounds_file(
                chain(ben_files, mal_files),
                toolkit,
                text_section_bounds_file,
                errors="ignore",
            )
    text_section_bounds = pd.read_csv(text_section_bounds_file, index_col="file").to_dict("index")
    text_section_bounds = {k: (v["lower"], v["upper"]) for k, v in text_section_bounds.items()}

    # Truncate the benign files based upon requested number to use
    ben_files = ben_files[:n_benign]
    # TODO: implement a more intelligent selection method for the benign files, eg:
    # df = pd.read_csv("/home/lk3591/Documents/MalConv2/output_model/gct/cum_results.csv")
    # ben_files = df.sort_values(by=["ts_confs"])["ts_files"].tolist()[0 : n_benign // 2]
    # ben_files += df.sort_values(by=["tr_confs"])["tr_files"].tolist()[0 : n_benign // 2]

    # Truncate the malicious files based upon their text section bounds
    def include_mal_file(f: str):
        return (
            f in text_section_bounds
            and ((text_section_bounds[f][0] >= min_size) if isinstance(min_size, int) else True)
            and ((text_section_bounds[f][1] <= max_size) if isinstance(max_size, int) else True)
        )

    def sort_mal_file(f: str):
        return text_section_bounds[f][1] - text_section_bounds[f][0]

    mal_files = [f for f in mal_files if include_mal_file(f.as_posix())]
    mal_files.sort(key=lambda f: sort_mal_file(f.as_posix()))

    # Slice the malicious files, skipping based upon the skip_idx and skip_val
    if skip_val is not None and isinstance(skip_val, str):
        skip_idx = [p.as_posix() for p in mal_files].index(skip_val)
    if skip_idx is not None and skip_idx > 0:
        mal_files = mal_files[skip_idx:]

    mal_files_splits = list(batch(mal_files, ceil_divide(len(mal_files), n_workers)))
    args = [
        (
            mal_files,
            run_flags,
            chunk_size,
            model,
            attributions_path,
            confidences_path,
            text_section_bounds,
            br_d,
            br_a,
            ben_files,
            control.get("errors"),
            control.getboolean("verbose"),
        )
        for mal_files in mal_files_splits
    ]

    print(f"run START @{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    start = time.time()

    # Single processor
    if n_workers == 1:
        run_samples(*args[0])
    # Concurrent (does not work very well)
    else:
        with multiprocessing.Pool(processes=n_workers) as pool:
            pool.starmap(run_samples, args, chunksize=1)

    # TODO: clean up run_swaps_count
    # if run_flags.getboolean("run_swaps_count"):
    #     attributions_file = attributions_path / f"{f.name}.pt"
    #     attributions = torch.load(attributions_file, map_location=device)[l:u]
    #     threshold = 0.0
    #     n_swaps = swaps_count(attributions, chunk_size, threshold)
    #     swaps_count_log = output_path / f"swaps_count_{threshold}.txt"
    #     with open(swaps_count_log, "a") as handle:
    #         handle.write(f"{f.as_posix()}, {n_swaps}\n")

    print(f"run DONE @{datetime.now()} in {time.time() - start:.2f}s")


def plot_proportion_negative_vs_swap_absolute(
    data: tp.Dict[str, np.ndarray],
    chunk_size: int,
    mode: tp.Literal["last", "any"],
    **outfile_kwargs,
) -> None:
    lengths = {k: len(confs) for k, confs in data.items()}
    max_iterations = max(lengths.values())
    n_neg_clfs = np.zeros(max_iterations)
    for itr in range(max_iterations):
        for k, confs in sorted(data.items(), key=lambda x: x[0]):
            if mode == "any":
                if any(c < CONFIDENCE_THRESHOLD for c in confs[:itr]):
                    n_neg_clfs[itr] += 1
            elif mode == "last":
                c = confs[itr] if itr < lengths[k] else confs[-1]
                if c < CONFIDENCE_THRESHOLD:
                    n_neg_clfs[itr] += 1
            else:
                raise ValueError(f"Invalid mode: {mode}")

    p_neg_clfs = n_neg_clfs / len(data)

    # Plot one
    fig, ax = plt.subplots()
    ax.plot(chunk_size * np.arange(max_iterations), 100 * p_neg_clfs)
    ax.set_ylim([0, 100])
    ax.set_title("False Negative Classification vs Bytes Swapped")
    ax.set_xlabel("Bytes Swapped in .text Section")
    ax.set_ylabel("Percent Classified as Benign")

    if "outfile_stem" not in outfile_kwargs:
        outfile_kwargs["outfile_stem"] = f"proportion_negative_vs_swap_absolute_{mode}"
    if "outfile_suffix" not in outfile_kwargs:
        outfile_kwargs["outfile_suffix"] = ".png"
    fig.savefig(get_outfile(**outfile_kwargs), dpi=400)


def plot_proportion_negative_vs_swap_proportion(
    data: tp.Dict[str, np.ndarray],
    mode: tp.Literal["last", "any"],
    granularity: int = 100,
    **outfile_kwargs,
) -> None:
    n_neg_clfs = np.zeros(granularity)

    for p in range(granularity):
        for k, confs in sorted(data.items(), key=lambda x: x[0]):
            itr = p * len(confs) // granularity
            if mode == "any":
                if any(c < CONFIDENCE_THRESHOLD for c in confs[:itr]):
                    n_neg_clfs[p] += 1
            elif mode == "last":
                c = confs[itr]
                if c < CONFIDENCE_THRESHOLD:
                    n_neg_clfs[p] += 1
            else:
                raise ValueError(f"Invalid mode: {mode}")

    p_neg_clfs = n_neg_clfs / len(data)

    # Plot one
    fig, ax = plt.subplots()
    ax.plot(np.arange(granularity), 100 * p_neg_clfs)
    ax.set_ylim([0, 100])
    ax.set_title("False Negative Classification vs Bytes Swapped")
    ax.set_xlabel("Percent Bytes Swapped in .text Section")
    ax.set_ylabel("Percent Classified as Benign")

    if "outfile_stem" not in outfile_kwargs:
        outfile_kwargs["outfile_stem"] = f"proportion_negative_vs_swap_proportion_{mode}"
    if "outfile_suffix" not in outfile_kwargs:
        outfile_kwargs["outfile_suffix"] = ".png"
    fig.savefig(get_outfile(**outfile_kwargs), dpi=400)


# TODO: the initial true positives data could be gathered from different files?
def analyze_inc_and_full(
    analysis_path: Path,
    modes_paths: tp.Dict[str, Path],
    chunk_size: int,
    only_common_files: bool = False,
) -> None:
    files = {m: set(f.name for f in p.iterdir()) for m, p in modes_paths.items()}
    if not all(file_set == next(iter(files.values())) for file_set in files):
        print(f"WARNING: files sets are not the same across modes: {only_common_files=}")
        if only_common_files:
            common_files = next(iter(files.values())).intersection(*files.values())
            files = {m: common_files for m in modes_paths}

    avg_conf_diff, prop_cls_flipped = {}, {}
    for m in tqdm(modes_paths):
        init_tp, init_fp, conf_diff, num_flipped = 0, 0, 0, 0
        confs_data = {}
        files_to_analyze = [p for p in modes_paths[m].iterdir() if p.name in files[m]]
        for f in tqdm(files_to_analyze, leave=False):
            confs = np.loadtxt(f, delimiter="\n")
            confs = np.expand_dims(confs, axis=0) if not confs.shape else confs
            confs_data[f.stem] = confs
            if len(confs) > 1 and confs[0] > CONFIDENCE_THRESHOLD:
                conf_diff += confs[-1] - confs[0]
                init_tp += 1
                if confs[-1] < CONFIDENCE_THRESHOLD:
                    num_flipped += 1
            else:
                init_fp += 1

        outfile_parent = analysis_path / m
        plot_proportion_negative_vs_swap_absolute(
            confs_data,
            chunk_size,
            "any",
            outfile_parent=outfile_parent,
        )
        plot_proportion_negative_vs_swap_absolute(
            confs_data,
            chunk_size,
            "last",
            outfile_parent=outfile_parent,
        )
        plot_proportion_negative_vs_swap_proportion(
            confs_data,
            "any",
            outfile_parent=outfile_parent,
        )
        plot_proportion_negative_vs_swap_proportion(
            confs_data,
            "last",
            outfile_parent=outfile_parent,
        )
        avg_conf_diff[m] = conf_diff / init_tp
        prop_cls_flipped[m] = num_flipped / init_tp

    return avg_conf_diff, prop_cls_flipped, init_tp, init_fp


def analyze_multi_full(
    analysis_path: Path,
    modes_paths: tp.Dict[str, Path],
    chunk_size: int,
):
    for m, p in tqdm(list(modes_paths.items())):
        # mal_files = list(p.iterdir())
        # sub_files = pd.read_csv(mal_files[0])["substitute"].tolist()
        # confs = [pd.read_csv(f)["confidences"].numpy() for f in mal_files]
        # # Each row corresponds to a different substitute file
        # confs = np.stack(confs, axis=0)
        outpath = analysis_path / m
        outpath.mkdir(exist_ok=True)

        cum_df, flipped_df = None, None
        n_total, n_cls_pos = 0, 0
        for f in tqdm(list(p.iterdir()), leave=False):
            n_total += 1
            df = pd.read_csv(f, index_col=0)  # Uses the filenames as the index
            cum_df = df if cum_df is None else cum_df + df
            # The NaN index corresponds to the initial confidence
            if df.loc[df.index.isnull()]["confidences"].item() > CONFIDENCE_THRESHOLD:
                n_cls_pos += 1
                cls_neg_df = -1 * (df.round().astype(np.int16) - 1)
                flipped_df = cls_neg_df if flipped_df is None else flipped_df + cls_neg_df

        avg_df = cum_df / n_total
        if avg_df.isnull().values.any():
            raise ValueError("NaNs in the average dataframe!")
        avg_df.sort_values(by=["confidences"]).to_csv(outpath / "average.csv")

        print(flipped_df)
        avg_flipped_df = flipped_df / n_cls_pos
        if avg_flipped_df.isnull().values.any():
            raise ValueError("NaNs in the average dataframe!")
        avg_flipped_df.sort_values(by=["confidences"]).to_csv(outpath / "average_flipped.csv")


# TODO: output results to files
def analyze(run_flags: SectionProxy, params: SectionProxy) -> None:
    output_path = get_output_path(params)
    toolkit = params.get("toolkit")
    chunk_size = params.getint("chunk_size")

    confidences_path = output_path / "confidences" / toolkit
    analysis_path = confidences_path / "analysis"
    analysis_path.mkdir(exist_ok=True)

    modes_paths = {
        m: confidences_path / m
        for m in INC_MODES + FULL_MODES
        if run_flags.getboolean("run_" + m, False)
    }
    if modes_paths:
        for m in modes_paths:
            (analysis_path / m).mkdir(exist_ok=True)
        avg_conf_diff, prop_cls_flipped, init_tp, init_fp = analyze_inc_and_full(
            analysis_path,
            modes_paths,
            chunk_size,
            only_common_files=True,
        )

    modes_paths = {
        m: confidences_path / m for m in MULTI_FULL_MODES if run_flags.getboolean("run_" + m, False)
    }
    if modes_paths:
        for m in modes_paths:
            (analysis_path / m).mkdir(exist_ok=True)
        analyze_multi_full(analysis_path, modes_paths, chunk_size)


def _verify_inc_and_full_same():
    # Only differences should be in the random method
    root = Path("outputs/7/KernelShap/False/256/50/1/confidences/pefile")
    paths = {
        "baseline": (root / "inc_baseline", root / "full_baseline"),
        "random": (root / "inc_random", root / "full_random"),
        "benign": (
            root / "inc_benign_corresponding",
            root / "full_benign_corresponding",
        ),
    }
    data = {k: [] for k in paths}
    for k, (inc_path, full_path) in paths.items():
        for f_inc in inc_path.iterdir():
            f_full = full_path / f_inc.name
            inc = np.loadtxt(f_inc, delimiter="\n")
            full = np.loadtxt(f_full, delimiter="\n")
            if not inc.shape:
                print(f_inc)
            if not full.shape:
                print(f_full)
            inc = np.expand_dims(inc, 0) if not inc.shape else inc
            full = np.expand_dims(full, 0) if not inc.shape else inc
            if inc[-1] != full[-1]:
                data[k].append((f_inc.name, inc, full))
    return data


if __name__ == "__main__":
    parser = ArgumentParser()
    parser.add_argument(
        "--config_file", type=str, default="config_files/modify_malware/default.ini"
    )
    args = parser.parse_args()

    config = ConfigParser(allow_no_value=True)
    config.read(args.config_file)

    run_flags = config["RUN_FLAGS"]
    control = config["CONTROL"]
    params = config["PARAMS"]

    if run_flags.getboolean("run"):
        run(run_flags, params, control)
    if run_flags.getboolean("analyze"):
        results = analyze(run_flags, params)
        pprint(results)
